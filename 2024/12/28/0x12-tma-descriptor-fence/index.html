<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>0x12 TMA Descriptor Fence 详解：Device-Side Descriptor 修改与同步 - CUTLASS 学习笔记</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#0d1117"><meta name="application-name" content="CUTLASS 学习笔记"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="msapplication-TileColor" content="#0d1117"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="CUTLASS 学习笔记"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="本文详细解析 CUTLASS 中 TMA Descriptor 的 device-side 修改机制，包括三个关键的 fence 函数：tma_descriptor_cp_fence_release、tma_descriptor_fence_release 和 tma_descriptor_fence_acquire。"><meta property="og:type" content="blog"><meta property="og:title" content="0x12 TMA Descriptor Fence 详解：Device-Side Descriptor 修改与同步"><meta property="og:url" content="https://drxuqian.github.io/2024/12/28/0x12-tma-descriptor-fence/"><meta property="og:site_name" content="CUTLASS 学习笔记"><meta property="og:description" content="本文详细解析 CUTLASS 中 TMA Descriptor 的 device-side 修改机制，包括三个关键的 fence 函数：tma_descriptor_cp_fence_release、tma_descriptor_fence_release 和 tma_descriptor_fence_acquire。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://drxuqian.github.io/img/og_image.png"><meta property="article:published_time" content="2024-12-28T02:00:00.000Z"><meta property="article:modified_time" content="2025-12-28T11:57:46.757Z"><meta property="article:author" content="DrXuQian"><meta property="article:tag" content="CUTLASS"><meta property="article:tag" content="CuTe"><meta property="article:tag" content="SM90"><meta property="article:tag" content="TMA"><meta property="article:tag" content="Hopper"><meta property="article:tag" content="Descriptor"><meta property="article:tag" content="Fence"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://drxuqian.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://drxuqian.github.io/2024/12/28/0x12-tma-descriptor-fence/"},"headline":"0x12 TMA Descriptor Fence 详解：Device-Side Descriptor 修改与同步","image":["https://drxuqian.github.io/img/og_image.png"],"datePublished":"2024-12-28T02:00:00.000Z","dateModified":"2025-12-28T11:57:46.757Z","author":{"@type":"Person","name":"DrXuQian"},"publisher":{"@type":"Organization","name":"CUTLASS 学习笔记","logo":{"@type":"ImageObject","url":"https://drxuqian.github.io/img/logo.svg"}},"description":"本文详细解析 CUTLASS 中 TMA Descriptor 的 device-side 修改机制，包括三个关键的 fence 函数：tma_descriptor_cp_fence_release、tma_descriptor_fence_release 和 tma_descriptor_fence_acquire。"}</script><link rel="canonical" href="https://drxuqian.github.io/2024/12/28/0x12-tma-descriptor-fence/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link data-pjax rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-dark.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 8.1.1"><link rel="stylesheet" href="/css/custom.css"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="CUTLASS 学习笔记" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/DrXuQian"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-12-28T02:00:00.000Z" title="12/28/2024, 10:00:00 AM">2024-12-28</time>发表</span><span class="level-item"><time dateTime="2025-12-28T11:57:46.757Z" title="12/28/2025, 7:57:46 PM">2025-12-28</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/CUTLASS/">CUTLASS</a></span><span class="level-item">14 分钟读完 (大约2116个字)</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">0x12 TMA Descriptor Fence 详解：Device-Side Descriptor 修改与同步</h1><div class="content"><p>本文详细解析 CUTLASS 中 TMA Descriptor 的 device-side 修改机制，包括三个关键的 fence 函数：<code>tma_descriptor_cp_fence_release</code>、<code>tma_descriptor_fence_release</code> 和 <code>tma_descriptor_fence_acquire</code>。</p>
<span id="more"></span>

<h2 id="背景：为什么需要-Device-Side-Descriptor-修改？"><a href="#背景：为什么需要-Device-Side-Descriptor-修改？" class="headerlink" title="背景：为什么需要 Device-Side Descriptor 修改？"></a>背景：为什么需要 Device-Side Descriptor 修改？</h2><p>在标准 TMA 使用场景中，TMA Descriptor 在 host 端创建（通过 <code>cuTensorMapEncode</code>），然后传递给 kernel 使用。但在某些场景下，需要在 device 端动态修改 descriptor：</p>
<h3 id="Array-GEMM-Batched-GEMM"><a href="#Array-GEMM-Batched-GEMM" class="headerlink" title="Array GEMM (Batched GEMM)"></a>Array GEMM (Batched GEMM)</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 多个 batch 共享相同的 shape，但地址不同</span></span><br><span class="line">ptr_A[] = [ptr_A0, ptr_A1, ptr_A2, ...]</span><br><span class="line">ptr_B[] = [ptr_B0, ptr_B1, ptr_B2, ...]</span><br></pre></td></tr></table></figure>

<p>每个 batch 处理完后，需要切换到下一个 batch 的地址。</p>
<h3 id="Grouped-GEMM"><a href="#Grouped-GEMM" class="headerlink" title="Grouped GEMM"></a>Grouped GEMM</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 每个 group 的矩阵形状可能不同</span></span><br><span class="line">Group <span class="number">0</span>: M=<span class="number">1024</span>, N=<span class="number">512</span>, K=<span class="number">256</span></span><br><span class="line">Group <span class="number">1</span>: M=<span class="number">2048</span>, N=<span class="number">1024</span>, K=<span class="number">512</span></span><br><span class="line">Group <span class="number">2</span>: M=<span class="number">512</span>, N=<span class="number">256</span>, K=<span class="number">128</span></span><br></pre></td></tr></table></figure>

<p>每个 group 需要修改 descriptor 的地址、dims 和 strides。</p>
<h2 id="三个-Fence-函数"><a href="#三个-Fence-函数" class="headerlink" title="三个 Fence 函数"></a>三个 Fence 函数</h2><p>位于 <a href="include/cute/arch/copy_sm90_desc.hpp">include&#x2F;cute&#x2F;arch&#x2F;copy_sm90_desc.hpp</a>：</p>
<h3 id="1-tma-descriptor-cp-fence-release"><a href="#1-tma-descriptor-cp-fence-release" class="headerlink" title="1. tma_descriptor_cp_fence_release"></a>1. tma_descriptor_cp_fence_release</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">tma_descriptor_cp_fence_release</span><span class="params">(TmaDescriptor <span class="type">const</span>* gmem_desc_ptr,</span></span></span><br><span class="line"><span class="params"><span class="function">                                      TmaDescriptor&amp; smem_desc)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">asm</span> <span class="title">volatile</span> <span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="string">&quot;tensormap.cp_fenceproxy.global.shared::cta.tensormap::generic.release.gpu.sync.aligned [%0], [%1], 128;&quot;</span></span></span></span><br><span class="line"><span class="params"><span class="function">    :: <span class="string">&quot;l&quot;</span>(gmem_int_desc), <span class="string">&quot;r&quot;</span>(smem_int_desc))</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>关键理解</strong>：这是一个 <strong>SMEM → GMEM</strong> 的拷贝操作！</p>
<ul>
<li><code>[%0]</code> &#x3D; GMEM 地址 (dst)</li>
<li><code>[%1]</code> &#x3D; SMEM 地址 (src)</li>
<li>指令格式：<code>tensormap.cp_fenceproxy.global.shared::cta</code> &#x3D; 从 <code>shared::cta</code> 拷贝到 <code>global</code></li>
</ul>
<p><strong>作用</strong>：</p>
<ol>
<li>将 SMEM 中修改后的 descriptor 拷贝回 GMEM</li>
<li>执行 release fence，确保修改对 TMA Unit 可见</li>
</ol>
<h3 id="2-tma-descriptor-fence-release"><a href="#2-tma-descriptor-fence-release" class="headerlink" title="2. tma_descriptor_fence_release"></a>2. tma_descriptor_fence_release</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">tma_descriptor_fence_release</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">asm</span> <span class="title">volatile</span> <span class="params">(<span class="string">&quot;fence.proxy.tensormap::generic.release.gpu;&quot;</span>)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>作用</strong>：直接在 GMEM 中修改 descriptor 后使用的 release fence。</p>
<h3 id="3-tma-descriptor-fence-acquire"><a href="#3-tma-descriptor-fence-acquire" class="headerlink" title="3. tma_descriptor_fence_acquire"></a>3. tma_descriptor_fence_acquire</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">tma_descriptor_fence_acquire</span><span class="params">(TmaDescriptor <span class="type">const</span>* desc_ptr)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">asm</span> <span class="title">volatile</span> <span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="string">&quot;fence.proxy.tensormap::generic.acquire.gpu [%0], 128;&quot;</span></span></span></span><br><span class="line"><span class="params"><span class="function">    :: <span class="string">&quot;l&quot;</span>(gmem_int_desc)</span></span></span><br><span class="line"><span class="params"><span class="function">    : <span class="string">&quot;memory&quot;</span>)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>作用</strong>：Invalidate TMA Unit 的 descriptor cache，确保 TMA Unit 重新读取 GMEM 中的最新 descriptor。</p>
<h2 id="TMA-Unit-的-Descriptor-Cache"><a href="#TMA-Unit-的-Descriptor-Cache" class="headerlink" title="TMA Unit 的 Descriptor Cache"></a>TMA Unit 的 Descriptor Cache</h2><p>TMA Unit 是独立于 SM 的硬件单元，有自己专用的 descriptor cache：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">┌─────────────────────────────────────────────────────────────┐</span><br><span class="line">│                          GPU                                 │</span><br><span class="line">│  ┌─────────┐  ┌─────────┐  ┌─────────┐                      │</span><br><span class="line">│  │   SM0   │  │   SM1   │  │   SM2   │  ...                 │</span><br><span class="line">│  │ ┌─────┐ │  │ ┌─────┐ │  │ ┌─────┐ │                      │</span><br><span class="line">│  │ │ L1  │ │  │ │ L1  │ │  │ │ L1  │ │                      │</span><br><span class="line">│  │ └─────┘ │  │ └─────┘ │  │ └─────┘ │                      │</span><br><span class="line">│  └─────────┘  └─────────┘  └─────────┘                      │</span><br><span class="line">│        │            │            │                           │</span><br><span class="line">│        └────────────┼────────────┘                           │</span><br><span class="line">│                     ▼                                        │</span><br><span class="line">│              ┌───────────┐                                   │</span><br><span class="line">│              │    L2     │                                   │</span><br><span class="line">│              └───────────┘                                   │</span><br><span class="line">│                     │                                        │</span><br><span class="line">│        ┌────────────┼────────────┐                           │</span><br><span class="line">│        ▼            ▼            ▼                           │</span><br><span class="line">│  ┌──────────┐ ┌──────────┐ ┌──────────┐                     │</span><br><span class="line">│  │ TMA Unit │ │ TMA Unit │ │ TMA Unit │  (per GPC/TPC)      │</span><br><span class="line">│  │┌────────┐│ │┌────────┐│ │┌────────┐│                     │</span><br><span class="line">│  ││  Desc  ││ ││  Desc  ││ ││  Desc  ││  ← TMA专用缓存      │</span><br><span class="line">│  ││ Cache  ││ ││ Cache  ││ ││ Cache  ││                     │</span><br><span class="line">│  │└────────┘│ │└────────┘│ │└────────┘│                     │</span><br><span class="line">│  └──────────┘ └──────────┘ └──────────┘                     │</span><br><span class="line">│                     │                                        │</span><br><span class="line">│                     ▼                                        │</span><br><span class="line">│              ┌───────────┐                                   │</span><br><span class="line">│              │   GMEM    │  (HBM)                           │</span><br><span class="line">│              └───────────┘                                   │</span><br><span class="line">└─────────────────────────────────────────────────────────────┘</span><br></pre></td></tr></table></figure>

<p><strong>关键点</strong>：</p>
<ul>
<li>TMA Unit 的 cache 与 SM 的 L1&#x2F;L2 是独立的</li>
<li>普通的 <code>__threadfence()</code> 无法影响 TMA Unit 的 cache</li>
<li>必须使用 <code>fence.proxy.tensormap</code> 来 invalidate TMA 的 descriptor cache</li>
</ul>
<h2 id="完整的-Descriptor-修改流程"><a href="#完整的-Descriptor-修改流程" class="headerlink" title="完整的 Descriptor 修改流程"></a>完整的 Descriptor 修改流程</h2><h3 id="Array-GEMM-场景（只修改地址）"><a href="#Array-GEMM-场景（只修改地址）" class="headerlink" title="Array GEMM 场景（只修改地址）"></a>Array GEMM 场景（只修改地址）</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1. 在 SMEM 中修改 descriptor 的地址</span></span><br><span class="line">tensormap.replace.tile.global_address [smem_desc], new_ptr;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. syncwarp 确保 warp 内所有线程完成修改</span></span><br><span class="line">__syncwarp();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3. cp_fence_release: SMEM→GMEM + release fence</span></span><br><span class="line">tensormap.cp_fenceproxy.global.shared::cta [gmem_desc], [smem_desc], <span class="number">128</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 4. fence_acquire: invalidate TMA Unit 的 descriptor cache</span></span><br><span class="line">fence.proxy.tensormap::generic.acquire.gpu [gmem_desc], <span class="number">128</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 5. 现在可以用更新后的 descriptor 执行 TMA 操作</span></span><br><span class="line">cp.async.bulk.tensor ...</span><br></pre></td></tr></table></figure>

<h3 id="Grouped-GEMM-场景（修改地址-dims-strides）"><a href="#Grouped-GEMM-场景（修改地址-dims-strides）" class="headerlink" title="Grouped GEMM 场景（修改地址 + dims + strides）"></a>Grouped GEMM 场景（修改地址 + dims + strides）</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1. 修改地址</span></span><br><span class="line">tensormap.replace.tile.global_address [smem_desc], new_ptr;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. 修改维度</span></span><br><span class="line">tensormap.replace.tile.global_dim [smem_desc], dim0, new_dim0;</span><br><span class="line">tensormap.replace.tile.global_dim [smem_desc], dim1, new_dim1;</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3. 修改步长</span></span><br><span class="line">tensormap.replace.tile.global_stride [smem_desc], ord0, new_stride0;</span><br><span class="line">tensormap.replace.tile.global_stride [smem_desc], ord1, new_stride1;</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 4-6. 同上的同步流程</span></span><br></pre></td></tr></table></figure>

<h2 id="CUTLASS-中的实现"><a href="#CUTLASS-中的实现" class="headerlink" title="CUTLASS 中的实现"></a>CUTLASS 中的实现</h2><h3 id="tensormaps-replace-global-address"><a href="#tensormaps-replace-global-address" class="headerlink" title="tensormaps_replace_global_address"></a>tensormaps_replace_global_address</h3><p>只修改地址，用于 Array GEMM：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// sm90_mma_array_tma_gmma_ss_warpspecialized.hpp:660-665</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">tensormaps_replace_global_address</span><span class="params">(..., <span class="type">int32_t</span> next_batch)</span> </span>&#123;</span><br><span class="line">  cute::<span class="built_in">tma_descriptor_replace_addr_in_shared_mem</span>(</span><br><span class="line">      shared_tensormaps.smem_tensormap_A,</span><br><span class="line">      mainloop_params.ptr_A[next_batch]);</span><br><span class="line">  cute::<span class="built_in">tma_descriptor_replace_addr_in_shared_mem</span>(</span><br><span class="line">      shared_tensormaps.smem_tensormap_B,</span><br><span class="line">      mainloop_params.ptr_B[next_batch]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="tensormaps-replace-global-tensor-properties"><a href="#tensormaps-replace-global-tensor-properties" class="headerlink" title="tensormaps_replace_global_tensor_properties"></a>tensormaps_replace_global_tensor_properties</h3><p>修改 dims 和 strides，用于 Grouped GEMM：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// sm90_mma_array_tma_gmma_ss_warpspecialized.hpp:671-710</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">tensormaps_replace_global_tensor_properties</span><span class="params">(...)</span> </span>&#123;</span><br><span class="line">  <span class="type">const</span> <span class="type">uint32_t</span> M = <span class="built_in">get</span>&lt;<span class="number">0</span>&gt;(problem_shape_mnkl);</span><br><span class="line">  <span class="type">const</span> <span class="type">uint32_t</span> N = <span class="built_in">get</span>&lt;<span class="number">1</span>&gt;(problem_shape_mnkl);</span><br><span class="line">  <span class="type">const</span> <span class="type">uint32_t</span> K = <span class="built_in">get</span>&lt;<span class="number">2</span>&gt;(problem_shape_mnkl);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 构建新的 shape 和 stride</span></span><br><span class="line">  cute::array&lt;<span class="type">uint32_t</span>, 5&gt; prob_shape_A  = &#123;<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>&#125;;</span><br><span class="line">  cute::array&lt;<span class="type">uint64_t</span>, 5&gt; prob_stride_A = &#123;<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>&#125;;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 从参数获取该 group 的 stride</span></span><br><span class="line">  Tensor tensor_a = <span class="built_in">make_tensor</span>(ptr_A, <span class="built_in">make_shape</span>(M,K,Int&lt;<span class="number">1</span>&gt;&#123;&#125;),</span><br><span class="line">                                mainloop_params.dA[next_group]);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 填充 shape 和 stride</span></span><br><span class="line">  cute::detail::<span class="built_in">fill_tma_gmem_shape_stride</span>(*observed_tma_load_a_, tensor_a,</span><br><span class="line">      prob_shape_A, prob_stride_A);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 用 tensormap.replace 指令修改 descriptor</span></span><br><span class="line">  cute::<span class="built_in">tma_descriptor_replace_dims_strides_in_shared_mem</span>(</span><br><span class="line">      shared_tensormaps.smem_tensormap_A,</span><br><span class="line">      prob_shape_A,</span><br><span class="line">      prob_stride_A);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="完整的-tensormaps-perform-update"><a href="#完整的-tensormaps-perform-update" class="headerlink" title="完整的 tensormaps_perform_update"></a>完整的 tensormaps_perform_update</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">tensormaps_perform_update</span><span class="params">(..., <span class="type">int32_t</span> next_batch)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (cute::<span class="built_in">elect_one_sync</span>()) &#123;</span><br><span class="line">    <span class="comment">// 1. 修改地址</span></span><br><span class="line">    <span class="built_in">tensormaps_replace_global_address</span>(shared_tensormaps, mainloop_params, next_batch);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 如果是 Grouped GEMM，还需要修改 dims 和 strides</span></span><br><span class="line">    <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(IsGroupedGemmKernel)</span> </span>&#123;</span><br><span class="line">      <span class="built_in">tensormaps_replace_global_tensor_properties</span>(shared_tensormaps,</span><br><span class="line">          mainloop_params, next_batch, problem_shape_mnkl);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="tensormaps-cp-fence-release"><a href="#tensormaps-cp-fence-release" class="headerlink" title="tensormaps_cp_fence_release"></a>tensormaps_cp_fence_release</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">tensormaps_cp_fence_release</span><span class="params">(TensorMapStorage&amp; shared_tensormaps,</span></span></span><br><span class="line"><span class="params"><span class="function">    cute::tuple&lt;TensorMapA, TensorMapB&gt; <span class="type">const</span>&amp; input_tensormaps)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (cute::<span class="built_in">elect_one_sync</span>()) &#123;</span><br><span class="line">    cute::<span class="built_in">tma_desc_commit_group</span>();</span><br><span class="line">    cute::<span class="built_in">tma_desc_wait_group</span>();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 整个 warp 必须执行这个操作（对齐要求）</span></span><br><span class="line">  <span class="built_in">tma_descriptor_cp_fence_release</span>(<span class="built_in">get</span>&lt;<span class="number">0</span>&gt;(input_tensormaps),</span><br><span class="line">                                   shared_tensormaps.smem_tensormap_A);</span><br><span class="line">  <span class="built_in">tma_descriptor_cp_fence_release</span>(<span class="built_in">get</span>&lt;<span class="number">1</span>&gt;(input_tensormaps),</span><br><span class="line">                                   shared_tensormaps.smem_tensormap_B);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="tensormaps-fence-acquire"><a href="#tensormaps-fence-acquire" class="headerlink" title="tensormaps_fence_acquire"></a>tensormaps_fence_acquire</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">tensormaps_fence_acquire</span><span class="params">(cute::tuple&lt;TensorMapA, TensorMapB&gt; <span class="type">const</span>&amp; input_tensormaps)</span> </span>&#123;</span><br><span class="line">  cute::<span class="built_in">tma_descriptor_fence_acquire</span>(<span class="built_in">get</span>&lt;<span class="number">0</span>&gt;(input_tensormaps));</span><br><span class="line">  cute::<span class="built_in">tma_descriptor_fence_acquire</span>(<span class="built_in">get</span>&lt;<span class="number">1</span>&gt;(input_tensormaps));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="数据流总结"><a href="#数据流总结" class="headerlink" title="数据流总结"></a>数据流总结</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Host GMEM descriptor (初始)</span><br><span class="line">        │</span><br><span class="line">        ▼ (初始拷贝到SMEM，kernel启动时)</span><br><span class="line">SMEM descriptor</span><br><span class="line">        │</span><br><span class="line">        ▼ tensormap.replace (在SMEM中修改)</span><br><span class="line">SMEM descriptor (修改后)</span><br><span class="line">        │</span><br><span class="line">        ▼ tensormap.cp_fenceproxy (SMEM→GMEM + release fence)</span><br><span class="line">GMEM descriptor (更新后)</span><br><span class="line">        │</span><br><span class="line">        ▼ fence.proxy.tensormap.acquire (invalidate TMA cache)</span><br><span class="line">TMA Unit 使用更新后的 descriptor</span><br></pre></td></tr></table></figure>

<h2 id="两种场景对比"><a href="#两种场景对比" class="headerlink" title="两种场景对比"></a>两种场景对比</h2><table>
<thead>
<tr>
<th>场景</th>
<th>每个 batch&#x2F;group 的矩阵</th>
<th>需要修改的字段</th>
<th>函数调用</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Array GEMM</strong></td>
<td>形状相同，地址不同</td>
<td><code>global_address</code></td>
<td><code>tensormaps_replace_global_address</code></td>
</tr>
<tr>
<td><strong>Grouped GEMM</strong></td>
<td>形状可能不同，地址不同</td>
<td><code>global_address</code> + <code>dims</code> + <code>strides</code></td>
<td><code>tensormaps_replace_global_address</code> + <code>tensormaps_replace_global_tensor_properties</code></td>
</tr>
</tbody></table>
<h2 id="为什么要这样设计？"><a href="#为什么要这样设计？" class="headerlink" title="为什么要这样设计？"></a>为什么要这样设计？</h2><p><strong>节省 host 端创建 descriptor 的开销</strong>：</p>
<ul>
<li>TMA descriptor 创建是 host 操作，需要调用 <code>cuTensorMapEncode</code></li>
<li>如果有 1000 个 batch&#x2F;group，需要创建 1000 个 descriptor，开销很大</li>
<li>通过在 device 端动态修改地址&#x2F;dims&#x2F;strides，只需要创建 <strong>1 个</strong> descriptor 模板</li>
</ul>
<h2 id="PTX-指令参考"><a href="#PTX-指令参考" class="headerlink" title="PTX 指令参考"></a>PTX 指令参考</h2><h3 id="tensormap-replace"><a href="#tensormap-replace" class="headerlink" title="tensormap.replace"></a>tensormap.replace</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// 修改地址</span><br><span class="line">tensormap.replace.tile.global_address.shared::cta.b1024.b64 [smem_desc], new_addr;</span><br><span class="line"></span><br><span class="line">// 修改维度</span><br><span class="line">tensormap.replace.tile.global_dim.shared::cta.b1024.b32 [smem_desc], dim_idx, new_dim;</span><br><span class="line"></span><br><span class="line">// 修改步长</span><br><span class="line">tensormap.replace.tile.global_stride.shared::cta.b1024.b64 [smem_desc], ord_idx, new_stride;</span><br></pre></td></tr></table></figure>

<h3 id="tensormap-cp-fenceproxy"><a href="#tensormap-cp-fenceproxy" class="headerlink" title="tensormap.cp_fenceproxy"></a>tensormap.cp_fenceproxy</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensormap.cp_fenceproxy.global.shared::cta.tensormap::generic.release.gpu.sync.aligned [gmem], [smem], 128;</span><br></pre></td></tr></table></figure>

<h3 id="fence-proxy-tensormap"><a href="#fence-proxy-tensormap" class="headerlink" title="fence.proxy.tensormap"></a>fence.proxy.tensormap</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// Release fence</span><br><span class="line">fence.proxy.tensormap::generic.release.gpu;</span><br><span class="line"></span><br><span class="line">// Acquire fence</span><br><span class="line">fence.proxy.tensormap::generic.acquire.gpu [gmem_desc], 128;</span><br></pre></td></tr></table></figure>

<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li><a href="include/cute/arch/copy_sm90_desc.hpp">CUTLASS Source: copy_sm90_desc.hpp</a></li>
<li><a href="include/cutlass/gemm/collective/sm90_mma_array_tma_gmma_ss_warpspecialized.hpp">CUTLASS Source: sm90_mma_array_tma_gmma_ss_warpspecialized.hpp</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/parallel-thread-execution/">PTX ISA: tensormap.cp_fenceproxy</a></li>
<li><a target="_blank" rel="noopener" href="https://nvidia.github.io/cccl/libcudacxx/ptx/instructions/tensormap.cp_fenceproxy.html">libcudacxx: tensormap.cp_fenceproxy</a></li>
</ul>
</div><div class="article-licensing box"><div class="licensing-title"><p>0x12 TMA Descriptor Fence 详解：Device-Side Descriptor 修改与同步</p><p><a href="https://drxuqian.github.io/2024/12/28/0x12-tma-descriptor-fence/">https://drxuqian.github.io/2024/12/28/0x12-tma-descriptor-fence/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>DrXuQian</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2024-12-28</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2025-12-28</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/CUTLASS/">CUTLASS</a><a class="link-muted mr-2" rel="tag" href="/tags/CuTe/">CuTe</a><a class="link-muted mr-2" rel="tag" href="/tags/SM90/">SM90</a><a class="link-muted mr-2" rel="tag" href="/tags/TMA/">TMA</a><a class="link-muted mr-2" rel="tag" href="/tags/Hopper/">Hopper</a><a class="link-muted mr-2" rel="tag" href="/tags/Descriptor/">Descriptor</a><a class="link-muted mr-2" rel="tag" href="/tags/Fence/">Fence</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2024/12/24/0x11-tiledmma-complete-guide/"><span class="level-item">0x11 CuTe TiledMMA 完全指南：从 Layout 到线程映射</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.jpg" alt="DrXuQian"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">DrXuQian</p><p class="is-size-6 is-block">CUDA/GPU Enthusiast</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives/"><p class="title">18</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories/"><p class="title">7</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags/"><p class="title">38</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/DrXuQian" target="_blank" rel="me noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="GitHub" href="https://github.com/DrXuQian"><i class="fab fa-github"></i></a></div></div></div><!--!--><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/CUDA/"><span class="level-start"><span class="level-item">CUDA</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/CUDA/CuTe/"><span class="level-start"><span class="level-item">CuTe</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/CUDA/CuTe/CUTLASS/"><span class="level-start"><span class="level-item">CUTLASS</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/CUDA/PTX/"><span class="level-start"><span class="level-item">PTX</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/CUDA/PTX/Hopper/"><span class="level-start"><span class="level-item">Hopper</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/CUTLASS/"><span class="level-start"><span class="level-item">CUTLASS</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/GPU-Computing/"><span class="level-start"><span class="level-item">GPU Computing</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-12-28T02:00:00.000Z">2024-12-28</time></p><p class="title"><a href="/2024/12/28/0x12-tma-descriptor-fence/">0x12 TMA Descriptor Fence 详解：Device-Side Descriptor 修改与同步</a></p><p class="categories"><a href="/categories/CUTLASS/">CUTLASS</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-12-24T09:00:00.000Z">2024-12-24</time></p><p class="title"><a href="/2024/12/24/0x11-tiledmma-complete-guide/">0x11 CuTe TiledMMA 完全指南：从 Layout 到线程映射</a></p><p class="categories"><a href="/categories/CUTLASS/">CUTLASS</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-12-24T08:00:00.000Z">2024-12-24</time></p><p class="title"><a href="/2024/12/24/0x10-warpgroup-mma-api/">0x10 CUTLASS SM90 WarpGroup MMA API 详解</a></p><p class="categories"><a href="/categories/CUTLASS/">CUTLASS</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-12-24T07:00:00.000Z">2024-12-24</time></p><p class="title"><a href="/2024/12/24/0x0F-thrfrg-c-analysis/">0x0F CuTe thrfrg_C 详解：C Tensor 的线程分片机制</a></p><p class="categories"><a href="/categories/CUTLASS/">CUTLASS</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-12-24T06:00:00.000Z">2024-12-24</time></p><p class="title"><a href="/2024/12/24/0x0E-cute-layout-divide/">0x0E CuTe Layout 分割操作：logical_divide 与 zipped_divide 详解</a></p><p class="categories"><a href="/categories/CUTLASS/">CUTLASS</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/12/"><span class="level-start"><span class="level-item">十二月 2024</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/CUTLASS/"><span class="tag">CUTLASS</span><span class="tag">15</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SM90/"><span class="tag">SM90</span><span class="tag">11</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CuTe/"><span class="tag">CuTe</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GMMA/"><span class="tag">GMMA</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TiledMMA/"><span class="tag">TiledMMA</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pipeline/"><span class="tag">Pipeline</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TMA/"><span class="tag">TMA</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/layout/"><span class="tag">layout</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/mbarrier/"><span class="tag">mbarrier</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PTX/"><span class="tag">PTX</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Layout/"><span class="tag">Layout</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/thrfrg-C/"><span class="tag">thrfrg_C</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hopper/"><span class="tag">Hopper</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/thread/"><span class="tag">thread</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/value/"><span class="tag">value</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/mma/"><span class="tag">mma</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/wgmma/"><span class="tag">wgmma</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ss-mode/"><span class="tag">ss-mode</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/rs-mode/"><span class="tag">rs-mode</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/tv-layout/"><span class="tag">tv-layout</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="CUTLASS 学习笔记" height="28"></a><p class="is-size-7"><span>&copy; 2025 DrXuQian</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客</span></p><p class="is-size-7">© 2024 DrXuQian</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="GitHub" href="https://github.com/DrXuQian"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/javascript" id="MathJax-script" async>MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      },
      chtml: {
        matchFontHeight: false
      }
    };</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script><script src="/js/pjax.js"></script><!--!--><!--!--><!--!--><script data-pjax src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script data-pjax src="/js/insight.js" defer></script><script data-pjax>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script><script src="/js/theme-toggle.js"></script></body></html>