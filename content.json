{"posts":[{"title":"CUTLASS Epilogue Fusion 架构详解","text":"本文档详细解释 SM90 Epilogue 和 Fusion 系统的完整架构。 本文档详细解释 SM90 Epilogue 和 Fusion 系统的完整架构。 1. 总体架构图123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596┌─────────────────────────────────────────────────────────────────────────────────────────────────┐│ CUTLASS SM90 Epilogue + Fusion 完整架构 │├─────────────────────────────────────────────────────────────────────────────────────────────────┤│ ││ ┌──────────────────────────────────────────────────────────────────────────────────────────┐ ││ │ 用户代码 │ ││ │ │ ││ │ // 选择融合操作类型 │ ││ │ using FusionOp = cutlass::epilogue::fusion::LinCombPerRowBiasEltAct&lt; │ ││ │ cutlass::epilogue::thread::ReLU, // 激活函数 │ ││ │ half_t, // 输出类型 │ ││ │ float, // 计算类型 │ ││ │ half_t // Bias 类型 │ ││ │ &gt;; │ ││ │ │ ││ │ // 配置 Epilogue │ ││ │ using CollectiveEpilogue = cutlass::epilogue::collective::CollectiveEpilogue&lt; │ ││ │ Sm90TmaWarpSpecialized&lt;4, 4, 2, false, false&gt;, // DispatchPolicy │ ││ │ TileShape, EpilogueTile, │ ││ │ ElementC, StrideC, ElementD, StrideD, │ ││ │ FusionCallbacks&lt;..., FusionOp, ...&gt;, // 融合回调 │ ││ │ ... │ ││ │ &gt;; │ ││ └──────────────────────────────────────────────────────────────────────────────────────────┘ ││ │ ││ ▼ ││ ┌──────────────────────────────────────────────────────────────────────────────────────────┐ ││ │ Template Dispatch Layer │ ││ │ │ ││ │ fusion/operations.hpp fusion/callbacks.hpp sm90_callbacks_*.hpp │ ││ │ ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────────┐ │ ││ │ │ FusionOperation │ │ FusionCallbacks │ │ FusionCallbacks │ │ ││ │ │ (元数据定义) │ ────────► │ (分发接口) │ ─────►│ 特化 (EVT 实现) │ │ ││ │ │ │ │ │ │ │ │ ││ │ │ • LinearComb │ │ 匹配 Policy + │ │ 继承自 Sm90EVT&lt;...&gt; │ │ ││ │ │ • LinCombBias │ │ Operation │ │ │ │ ││ │ │ • LinCombEltAct │ │ │ │ │ │ ││ │ └─────────────────┘ └─────────────────┘ └─────────────────────┘ │ ││ └──────────────────────────────────────────────────────────────────────────────────────────┘ ││ │ ││ ▼ ││ ┌──────────────────────────────────────────────────────────────────────────────────────────┐ ││ │ EVT (Expression Visitor Tree) │ ││ │ │ ││ │ 示例: LinCombPerRowBiasEltAct = ReLU(α * acc + β * C + bias) │ ││ │ │ ││ │ Sm90Compute&lt;ReLU&gt; ← 激活函数 │ ││ │ │ │ ││ │ Sm90Compute&lt;plus&gt; ← 加 bias │ ││ │ / \\ │ ││ │ Sm90RowBroadcast Sm90Compute&lt;multiply_add&gt; ← β*C + α*acc │ ││ │ (bias) / | \\ │ ││ │ Sm90Scalar Sm90SrcFetch Sm90EVT&lt;multiplies&gt; │ ││ │ (β) (C) / \\ │ ││ │ Sm90Scalar Sm90AccFetch │ ││ │ (α) (acc) │ ││ │ │ ││ │ EVT 节点类型: │ ││ │ • Leaf nodes: Sm90AccFetch, Sm90SrcFetch, Sm90ScalarBroadcast, Sm90RowBroadcast │ ││ │ • Internal nodes: Sm90Compute&lt;Op&gt; (Op = plus, multiplies, ReLU, GELU, etc.) │ ││ │ • Output nodes: Sm90AuxStore (可选的辅助输出) │ ││ └──────────────────────────────────────────────────────────────────────────────────────────┘ ││ │ ││ ▼ ││ ┌──────────────────────────────────────────────────────────────────────────────────────────┐ ││ │ CollectiveEpilogue 执行引擎 │ ││ │ │ ││ │ ┌─────────────────────────┐ ┌─────────────────────────┐ │ ││ │ │ Producer Load Warp │ │ Consumer Store Warps │ │ ││ │ │ (pld) │ │ (cst) │ │ ││ │ │ │ │ │ │ ││ │ │ • TMA load C │ SMEM │ • SMEM → Register │ │ ││ │ │ • TMA load bias │ ──────────► │ • EVT.visit() 计算 │ │ ││ │ │ • TMA load scale │ Pipeline │ • Register → SMEM │ │ ││ │ │ │ │ • TMA store D │ │ ││ │ └─────────────────────────┘ └─────────────────────────┘ │ ││ │ │ ││ │ Pipeline 同步 (mbarrier): │ ││ │ • Full Barrier: Producer → Consumer (数据就绪) │ ││ │ • Empty Barrier: Consumer → Producer (空间释放) │ ││ └──────────────────────────────────────────────────────────────────────────────────────────┘ ││ │ ││ ▼ ││ ┌──────────────────────────────────────────────────────────────────────────────────────────┐ ││ │ 硬件层 (SM90/Hopper) │ ││ │ │ ││ │ GMEM ◄────── TMA ──────► SMEM ◄────── Register File │ ││ │ ▲ │ ││ │ │ │ ││ │ mbarrier (64-bit) │ ││ │ ┌──────────────────────┐ │ ││ │ │ Phase │ PendingTX │ Arrival │ │ ││ │ │ 1-bit │ ~20-bit │ ~20-bit │ │ ││ │ └──────────────────────┘ │ ││ └──────────────────────────────────────────────────────────────────────────────────────────┘ │└─────────────────────────────────────────────────────────────────────────────────────────────────┘ 2. 具体示例：GEMM + Bias + ReLU2.1 用户代码示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;cutlass/cutlass.h&gt;#include &lt;cutlass/gemm/device/gemm_universal.h&gt;#include &lt;cutlass/epilogue/collective/collective_builder.hpp&gt;// 定义 GEMM 问题// D = ReLU(alpha * (A @ B) + beta * C + bias)using ElementA = cutlass::half_t;using ElementB = cutlass::half_t;using ElementC = cutlass::half_t;using ElementD = cutlass::half_t;using ElementBias = cutlass::half_t;using ElementCompute = float; // 累加和计算使用 FP32// Step 1: 选择融合操作using EpilogueOp = cutlass::epilogue::fusion::LinCombPerRowBiasEltAct&lt; cutlass::epilogue::thread::ReLU, // 激活函数 ElementD, // 输出类型 ElementCompute, // 计算类型 ElementBias, // Bias 类型 ElementC, // Source (C) 类型 ElementCompute // Scalar (alpha/beta) 类型&gt;;// Step 2: 使用 CollectiveBuilder 构建 Epilogueusing CollectiveEpilogue = typename cutlass::epilogue::collective::CollectiveBuilder&lt; cutlass::arch::Sm90, cutlass::arch::OpClassTensorOp, TileShape, // e.g., Shape&lt;_128, _128, _64&gt; ClusterShape, // e.g., Shape&lt;_1, _1, _1&gt; EpilogueTileType, ElementCompute, // Accumulator type ElementCompute, // Compute type ElementC, LayoutC, 128 / cutlass::sizeof_bits&lt;ElementC&gt;::value, // Alignment ElementD, LayoutD, 128 / cutlass::sizeof_bits&lt;ElementD&gt;::value, EpilogueOp // 融合操作&gt;::CollectiveOp;// Step 3: 配置运行时参数typename CollectiveEpilogue::Arguments epilogue_args { { alpha, // ElementCompute alpha beta, // ElementCompute beta nullptr, // alpha_ptr (optional) nullptr, // beta_ptr (optional) ptr_bias, // ElementBias const* ptr_bias {_0{}, _1{}, 0} // Stride for bias (per-row) }, ptr_C, // ElementC const* ptr_C {ldC, _1{}, 0}, // StrideC ptr_D, // ElementD* ptr_D {ldD, _1{}, 0} // StrideD}; 2.2 EVT 展开过程上述 LinCombPerRowBiasEltAct 在编译时展开为以下 EVT 结构： 1234567891011121314151617// 文件: sm90_callbacks_tma_warpspecialized.hpp// D = ReLU(alpha * acc + beta * C + bias)using Sm90LinCombPerRowBiasEltAct = Sm90EVT&lt;Sm90Compute&lt;ReLU, ElementD, ElementCompute, RoundStyle&gt;, // 根节点: ReLU Sm90EVT&lt;Sm90Compute&lt;plus, ElementCompute, ElementCompute&gt;, // 加 bias Sm90RowBroadcast&lt;ElementBias, Stride&lt;_1, _0, int64_t&gt;&gt;, // bias (per-row) Sm90EVT&lt;Sm90Compute&lt;multiply_add, ElementCompute, ElementCompute&gt;, // β*C + α*acc Sm90ScalarBroadcast&lt;ElementScalar&gt;, // β Sm90SrcFetch&lt;ElementC&gt;, // C Sm90EVT&lt;Sm90Compute&lt;multiplies, ElementCompute, ElementCompute&gt;, // α*acc Sm90ScalarBroadcast&lt;ElementScalar&gt;, // α Sm90AccFetch // acc (累加器) &gt; &gt; &gt; &gt;; 2.3 运行时执行流程12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667时间线──────────────────────────────────────────────────────────────────────────────►Producer Load Warp (pld) Consumer Store Warps (cst) │ │ ▼ │┌───────────────────────┐ ││ producer_acquire(s0) │ ││ • wait(empty[0]) │ ││ • expect_tx(full[0]) │ │└───────────────────────┘ │ │ │ ▼ │┌───────────────────────┐ ││ pld_callbacks.step() │ ││ • TMA load bias[0] │ ││ • TMA load C[0] │ │└───────────────────────┘ │ │ │ │ (TMA 完成, 硬件自动 complete_tx) │ │ full_barrier[0] phase flip ──────────────►│ │ ▼ │ ┌───────────────────────┐ │ │ consumer_wait(s0) │ │ │ • wait(full[0]) │ │ └───────────────────────┘ │ │ │ ▼ │ ┌───────────────────────┐ │ │ S2R: SMEM → Register │ │ │ • copy C to rC │ │ └───────────────────────┘ │ │ │ ▼ │ ┌───────────────────────┐ │ │ cst_callbacks.previsit│ │ │ • copy bias to rBias │ │ └───────────────────────┘ │ │ │ ▼ │ ┌───────────────────────────────────┐ │ │ cst_callbacks.visit() │ │ │ │ │ │ for (v = 0; v &lt; FragmentSize; v++)│ │ │ // EVT 后序遍历执行: │ │ │ acc_v = rAcc[v] │ │ │ t1 = α * acc_v │ │ │ t2 = β * rC[v] + t1 │ │ │ t3 = t2 + rBias[row] │ │ │ rD[v] = ReLU(t3) │ │ └───────────────────────────────────┘ │ │ │ ▼ │ ┌───────────────────────┐ │ │ R2S: Register → SMEM │ │ │ • copy rD to sD │ │ └───────────────────────┘ │ │◄───────────────────────────────────── │◄────────────┘ │ consumer_release(s0) │ │ arrive(empty[0]) ▼ ▼ ┌───────────────────────┐┌───────────────────────┐ │ TMA store D ││ producer_acquire(s1) │ │ • fence_async ││ • wait(empty[1]) │ │ • copy sD → GMEM ││ (可以继续加载下一个) │ └───────────────────────┘└───────────────────────┘ 3. 数据流详解3.1 SMEM 布局示例假设配置：StagesC=4, StagesD=4, EpilogueTile=(64, 64), ElementC=half_t 12345678910111213141516171819202122232425262728293031323334353637SharedStorage 内存布局:┌─────────────────────────────────────────────────────────────────────────┐│ TensorStorage │├─────────────────────────────────────────────────────────────────────────┤│ CollectiveStorage ││ ┌─────────────────────────────────────────────────────────────────────┐││ │ smem_C[4 stages] │││ │ ┌──────────┬──────────┬──────────┬──────────┐ │││ │ │ Stage 0 │ Stage 1 │ Stage 2 │ Stage 3 │ │││ │ │ 64x64 │ 64x64 │ 64x64 │ 64x64 │ │││ │ │ = 8 KB │ = 8 KB │ = 8 KB │ = 8 KB │ Total: 32 KB │││ │ └──────────┴──────────┴──────────┴──────────┘ │││ ├─────────────────────────────────────────────────────────────────────┤││ │ smem_D[4 stages] (或与 smem_C 共用 if ReuseSmemC) │││ │ ┌──────────┬──────────┬──────────┬──────────┐ │││ │ │ Stage 0 │ Stage 1 │ Stage 2 │ Stage 3 │ │││ │ │ 64x64 │ 64x64 │ 64x64 │ 64x64 │ Total: 32 KB │││ │ └──────────┴──────────┴──────────┴──────────┘ │││ └─────────────────────────────────────────────────────────────────────┘│├─────────────────────────────────────────────────────────────────────────┤│ FusionStorage (for bias, scale, aux) ││ ┌─────────────────────────────────────────────────────────────────────┐││ │ smem_bias[4 stages] │││ │ ┌──────────┬──────────┬──────────┬──────────┐ │││ │ │ Stage 0 │ Stage 1 │ Stage 2 │ Stage 3 │ │││ │ │ 64 elems │ 64 elems │ 64 elems │ 64 elems │ Total: 512 B │││ │ └──────────┴──────────┴──────────┴──────────┘ │││ └─────────────────────────────────────────────────────────────────────┘│├─────────────────────────────────────────────────────────────────────────┤│ PipelineStorage ││ ┌─────────────────────────────────────────────────────────────────────┐││ │ full_barrier[4] = 4 × 8 bytes = 32 bytes │││ │ empty_barrier[4] = 4 × 8 bytes = 32 bytes │││ │ Total: 64 bytes │││ └─────────────────────────────────────────────────────────────────────┘│└─────────────────────────────────────────────────────────────────────────┘Total SMEM: ~64 KB (without ReuseSmemC) or ~32 KB (with ReuseSmemC) 3.2 寄存器使用示例12345678910111213141516171819202122232425262728293031323334Thread 寄存器分配 (假设 FragmentSize=2, MMA 输出 8x8 per thread):┌─────────────────────────────────────────────────────────────────────────┐│ Per-Thread Register Usage │├─────────────────────────────────────────────────────────────────────────┤│ ││ Accumulator (from mainloop): ││ ┌─────────────────────────────────────────────────────────────────────┐││ │ rAcc[64] = 64 × FP32 = 256 bytes (from MMA, 8x8 elements) │││ └─────────────────────────────────────────────────────────────────────┘││ ││ Source C (loaded from SMEM): ││ ┌─────────────────────────────────────────────────────────────────────┐││ │ rC[64] = 64 × FP16 = 128 bytes (converted to FP32 for compute) │││ └─────────────────────────────────────────────────────────────────────┘││ ││ Bias (loaded from SMEM, broadcast per row): ││ ┌─────────────────────────────────────────────────────────────────────┐││ │ rBias[8] = 8 × FP16 = 16 bytes (8 rows) │││ └─────────────────────────────────────────────────────────────────────┘││ ││ Output D (computed result): ││ ┌─────────────────────────────────────────────────────────────────────┐││ │ rD[64] = 64 × FP16 = 128 bytes (output elements) │││ └─────────────────────────────────────────────────────────────────────┘││ ││ Scalar constants: ││ ┌─────────────────────────────────────────────────────────────────────┐││ │ alpha, beta = 2 × FP32 = 8 bytes │││ └─────────────────────────────────────────────────────────────────────┘││ ││ Approximate total: ~550 bytes per thread ││ For 256 threads/CTA: ~140 KB register usage │└─────────────────────────────────────────────────────────────────────────┘ 4. Pipeline 状态机4.1 PipelineState 结构12345678910111213141516template &lt;int Stages&gt;struct PipelineState { int index_ = 0; // 当前 stage (0 到 Stages-1) uint32_t phase_ = 0; // 当前 phase (0 或 1) uint32_t count_ = 0; // 总迭代次数 // 推进状态 void operator++() { ++index_; ++count_; if (index_ == Stages) { index_ = 0; // 循环回 0 phase_ ^= 1; // 翻转 phase } }}; 4.2 4-Stage Pipeline 状态转换示例12345678910111213141516171819时间 Producer State Consumer State 备注──── ────────────── ────────────── ────T0 (idx=0, ph=0, cnt=0) (idx=0, ph=0, cnt=0) 初始状态 ↓ ++T1 (idx=1, ph=0, cnt=1) (idx=0, ph=0, cnt=0) Producer 领先 ↓ ++T2 (idx=2, ph=0, cnt=2) (idx=0, ph=0, cnt=0) ↓ ++ ↓ ++T3 (idx=3, ph=0, cnt=3) (idx=1, ph=0, cnt=1) Consumer 开始追赶 ↓ ++ ↓ ++T4 (idx=0, ph=1, cnt=4) (idx=2, ph=0, cnt=2) Producer 绕回, phase 翻转 │ ↓ ++ │ wait(empty[0], ph=1) (idx=3, ph=0, cnt=3) Producer 必须等待 │ ↓ ++ │ (idx=0, ph=1, cnt=4) Consumer 绕回 │ │ │◄──── arrive(empty[0]) ┘ Consumer 释放 stage 0 ↓ ++T5 (idx=1, ph=1, cnt=5) ... Producer 可以继续 5. EVT 节点详解5.1 Leaf 节点 节点类型 数据来源 回调时机 示例 Sm90AccFetch 寄存器 (mainloop) visit() 获取累加器值 Sm90SrcFetch SMEM (C matrix) previsit() 加载 获取 C 矩阵值 Sm90ScalarBroadcast 参数 (alpha, beta) begin() 加载 广播标量到所有元素 Sm90RowBroadcast SMEM (bias) previsit() 加载 广播行向量 Sm90ColBroadcast SMEM (scale) previsit() 加载 广播列向量 5.2 Internal 节点12345678910111213141516171819// Sm90Compute 模板template &lt; template&lt;class&gt; class ComputeFn, // 计算函数 (plus, multiplies, ReLU, etc.) class ElementOutput, // 输出类型 class ElementCompute, // 计算类型 FloatRoundStyle RoundStyle // 舍入模式&gt;struct Sm90Compute { // visit() 执行计算 template &lt;typename Accumulator, typename... Inputs&gt; CUTLASS_DEVICE auto visit( Accumulator const&amp; acc, // 累加器片段 int epi_v, int epi_m, int epi_n, // 位置 Inputs const&amp;... inputs // 子节点输出 ) { // 应用计算函数 return ComputeFn&lt;ElementCompute&gt;{}(inputs...); }}; 5.3 常用计算函数12345678910// 二元操作template&lt;class T&gt; struct plus { T operator()(T a, T b) { return a + b; } };template&lt;class T&gt; struct multiplies { T operator()(T a, T b) { return a * b; } };template&lt;class T&gt; struct multiply_add{ T operator()(T a, T b, T c) { return a * b + c; } };// 激活函数template&lt;class T&gt; struct ReLU { T operator()(T x) { return max(T(0), x); } };template&lt;class T&gt; struct GELU { T operator()(T x) { return x * 0.5f * (1 + erf(x/sqrt(2))); } };template&lt;class T&gt; struct SiLU { T operator()(T x) { return x / (1 + exp(-x)); } };template&lt;class T&gt; struct Sigmoid { T operator()(T x) { return 1 / (1 + exp(-x)); } }; 6. 回调函数调用时序12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849┌─────────────────────────────────────────────────────────────────────────────────────┐│ Fusion Callbacks 调用时序 │├─────────────────────────────────────────────────────────────────────────────────────┤│ ││ Producer Load Warp: ││ ┌────────────────────────────────────────────────────────────────────────────────┐ ││ │ pld_callbacks = fusion.get_producer_load_callbacks(args) │ ││ │ │ ││ │ pld_callbacks.begin() // 初始化, 加载 scalar 到寄存器 │ ││ │ │ │ ││ │ for each subtile (epi_m, epi_n): │ ││ │ │ pld_callbacks.step(barrier, epi_m, epi_n, ...) │ ││ │ │ │ // TMA 加载 bias, scale 等到 SMEM │ ││ │ │ └── TMA load C (if needed) │ ││ │ │ ││ │ pld_callbacks.end() // 清理 (通常为空) │ ││ └────────────────────────────────────────────────────────────────────────────────┘ ││ ││ Consumer Store Warps: ││ ┌────────────────────────────────────────────────────────────────────────────────┐ ││ │ cst_callbacks = fusion.get_consumer_store_callbacks&lt;RefSrc&gt;(args) │ ││ │ │ ││ │ cst_callbacks.begin() // 初始化 │ ││ │ │ │ ││ │ for each subtile (epi_m, epi_n): │ ││ │ │ cst_callbacks.begin_loop(epi_m, epi_n) │ ││ │ │ │ // per-subtile 初始化 │ ││ │ │ │ │ ││ │ │ │ [consumer_wait for C] │ ││ │ │ │ [S2R copy C to register] │ ││ │ │ │ │ ││ │ │ cst_callbacks.previsit(epi_m, epi_n, ...) │ ││ │ │ │ // SMEM → Register: bias, scale │ ││ │ │ │ │ ││ │ │ for each fragment v: │ ││ │ │ │ result[v] = cst_callbacks.visit(acc[v], v, epi_m, epi_n) │ ││ │ │ │ │ // ★ 核心计算: EVT 树求值 ★ │ ││ │ │ │ │ // D = ReLU(α*acc + β*C + bias) │ ││ │ │ │ │ ││ │ │ [R2S copy result to SMEM] │ ││ │ │ │ ││ │ │ cst_callbacks.tma_store(epi_m, epi_n, ...) │ ││ │ │ // TMA store 前的回调 (可选 aux store) │ ││ │ │ │ ││ │ │ [TMA store D] │ ││ │ │ ││ │ cst_callbacks.end() // 最终处理 (如 absmax reduction) │ ││ └────────────────────────────────────────────────────────────────────────────────┘ │└─────────────────────────────────────────────────────────────────────────────────────┘ 7. 性能调优参数 参数 默认值 影响 调优建议 StagesC 4 C 加载 pipeline 深度 增加可隐藏延迟，但消耗更多 SMEM StagesD 4 D 存储 pipeline 深度 通常与 StagesC 相同 FragmentSize 2 向量化宽度 2 for FP16, 1 for FP32 ReuseSmemC false C/D 共用 SMEM 节省 SMEM 但需更复杂同步 DelayTmaStore false 延迟 TMA store 提高指令交错，但增加延迟 EpilogueTile (64, 64) Subtile 大小 平衡并行度和寄存器压力 8. 相关源文件 文件 内容 epilogue/collective/sm90_epilogue_tma_warpspecialized.hpp CollectiveEpilogue 实现 epilogue/fusion/operations.hpp FusionOperation 定义 epilogue/fusion/callbacks.hpp FusionCallbacks 分发接口 epilogue/fusion/sm90_callbacks_tma_warpspecialized.hpp EVT 特化 epilogue/fusion/sm90_visitor_*.hpp EVT 节点实现 pipeline/sm90_pipeline.hpp Pipeline 实现 arch/barrier.h mbarrier PTX 封装","link":"/2024/12/23/epilogue-fusion-architecture/"},{"title":"CUTLASS Pipeline 接口到 PTX 指令映射","text":"本文档详细说明 CUTLASS SM90 Pipeline 接口如何映射到底层的 mbarrier PTX 指令。 本文档详细说明 CUTLASS SM90 Pipeline 接口如何映射到底层的 mbarrier PTX 指令。 1. 核心概念1.1 双 Barrier 架构Pipeline 使用双 Barrier 实现生产者-消费者同步： 1234567891011121314┌─────────────────────────────────────────────────────────────┐│ Pipeline Stage [i] ││ ││ ┌──────────────────┐ ┌──────────────────┐ ││ │ Full Barrier │ │ Empty Barrier │ ││ │ (数据就绪信号) │ │ (空间释放信号) │ ││ │ │ │ │ ││ │ ClusterTransaction│ │ ClusterBarrier │ ││ │ Barrier │ │ │ ││ └──────────────────┘ └──────────────────┘ ││ ↑ ↑ ││ Producer 写完 Consumer 用完 ││ 数据后 signal 数据后 signal │└─────────────────────────────────────────────────────────────┘ Barrier 类型 谁 Signal 谁 Wait 含义 Full Barrier ClusterTransactionBarrier Producer (TMA) Consumer “数据准备好了，可以读” Empty Barrier ClusterBarrier Consumer Producer “空间腾出来了，可以写” 1.2 SMEM 中的 Barrier 存储12345// sm90_pipeline.hppstruct SharedStorage { FullBarrier full_barrier_[Stages]; // ClusterTransactionBarrier (64-bit mbarrier) EmptyBarrier empty_barrier_[Stages]; // ClusterBarrier (64-bit mbarrier)}; 1.3 PipelineState 结构123456template &lt;int Stages_&gt;struct PipelineState { int index_ = 0; // 当前 stage (0 ~ Stages-1)，循环取模 uint32_t phase_ = 0; // 当前 phase (0 或 1)，每绕回一次翻转 uint32_t count_ = 0; // 总迭代次数}; 2. Pipeline 接口到 PTX 映射总览 Pipeline 接口 Barrier 类型 底层方法 PTX 指令 producer_acquire EmptyBarrier wait(phase) mbarrier.try_wait.parity (spin) producer_acquire (leader) FullBarrier arrive_and_expect_tx(bytes) mbarrier.arrive.expect_tx producer_commit FullBarrier TMA 硬件触发 mbarrier.complete_tx producer_get_barrier FullBarrier 返回指针 (无 PTX) producer_tail EmptyBarrier 循环 wait 所有 stages mbarrier.try_wait.parity consumer_try_wait FullBarrier try_wait(phase) mbarrier.try_wait.parity (单次) consumer_wait FullBarrier wait(phase) mbarrier.try_wait.parity (spin) consumer_release EmptyBarrier arrive(cta_id) mbarrier.arrive 3. Producer 接口详解3.1 producer_acquire功能：等待 stage 空间可用，并设置期望的传输字节数 12345678910// sm90_pipeline.hpp:512void producer_acquire(uint32_t stage, uint32_t phase) { // Step 1: 等待 Consumer 释放空间 empty_barrier_ptr_[stage].wait(phase); // Step 2: Leader 线程设置期望传输字节数 if (params_.is_leader) { full_barrier_ptr_[stage].arrive_and_expect_tx(params_.transaction_bytes); }} PTX (wait - 阻塞式 spin loop): 12345LAB_WAIT: mbarrier.try_wait.parity.shared::cta.b64 P1, [smem_addr], phase, 0x989680; @P1 bra DONE; bra LAB_WAIT;DONE: PTX (arrive_and_expect_tx): 1mbarrier.arrive.expect_tx.shared::cta.b64 _, [smem_addr], transaction_bytes; 3.2 producer_commit功能：TMA 传输完成后，硬件自动触发 barrier 完成 12// TMA 硬件自动执行，等价于:full_barrier_ptr_[stage].complete_transaction(bytes); PTX: 1mbarrier.complete_tx.shared::cluster.relaxed.cluster.b64 [smem_addr], transaction_bytes; 注意：通常不需要软件显式调用，TMA 指令会自动在传输完成后触发此操作。 3.3 producer_get_barrier功能：返回 Full Barrier 指针，用于 TMA descriptor 1234// sm90_pipeline.hpp:555ProducerBarrierType* producer_get_barrier(uint32_t stage) { return reinterpret_cast&lt;ProducerBarrierType*&gt;(&amp;full_barrier_ptr_[stage]);} 无 PTX 指令，仅返回 SMEM 地址供 TMA 使用。 3.4 producer_tail功能：防止 Producer block 过早退出，等待所有 stages 被 Consumer 释放 1234567// sm90_pipeline.hpp:448void producer_tail(PipelineState state) { for (int count = 0; count &lt; Stages; ++count) { empty_barrier_ptr_[state.index()].wait(state.phase()); ++state; }} PTX: 循环 Stages 次执行 mbarrier.try_wait.parity 4. Consumer 接口详解4.1 consumer_try_wait功能：非阻塞尝试等待数据就绪 12345678// sm90_pipeline.hpp:590ConsumerToken consumer_try_wait(uint32_t stage, uint32_t phase, uint32_t skip_wait) { if (skip_wait) { return {BarrierStatus::WaitDone}; } bool barrier_status = full_barrier_ptr_[stage].try_wait(phase); return {static_cast&lt;BarrierStatus&gt;(barrier_status)};} PTX (单次尝试，无 spin): 12mbarrier.try_wait.parity.shared::cta.b64 P1, [smem_addr], phase;selp.b32 result, 1, 0, P1; 返回值： BarrierStatus::WaitDone (1): 数据已就绪 BarrierStatus::WaitAgain (0): 数据未就绪，需要继续等待 4.2 consumer_wait功能：阻塞等待数据就绪 123456789101112// sm90_pipeline.hpp:611void consumer_wait(uint32_t stage, uint32_t phase) { full_barrier_ptr_[stage].wait(phase);}// 带 token 版本void consumer_wait(uint32_t stage, uint32_t phase, ConsumerToken barrier_token) { if (barrier_token == BarrierStatus::WaitAgain) { full_barrier_ptr_[stage].wait(phase); } // 如果 WaitDone，直接跳过} PTX (阻塞式 spin loop): 12345LAB_WAIT: mbarrier.try_wait.parity.shared::cta.b64 P1, [smem_addr], phase, 0x989680; @P1 bra DONE; bra LAB_WAIT;DONE: 4.3 consumer_release功能：通知 Producer 空间已释放 1234// sm90_pipeline.hpp:628void consumer_release(uint32_t stage, uint32_t skip = false) { empty_barrier_ptr_[stage].arrive(dst_blockid_, is_signaling_thread_ &amp; (!skip));} PTX (本地 CTA arrive): 1mbarrier.arrive.shared::cta.b64 _, [smem_addr]; PTX (远程 Cluster arrive): 12mapa.shared::cluster.u32 remAddr32, smem_addr, cta_id;mbarrier.arrive.shared::cluster.b64 _, [remAddr32]; 5. mbarrier 64-bit 结构123456789101112┌─────────────────────────────────────────────────────────────────┐│ mbarrier (64-bit) │├─────────────┬─────────────────────┬─────────────────────────────┤│ Phase Bit │ Pending TX Count │ Arrival Count ││ (1 bit) │ (~20 bits) │ (~20 bits) │├─────────────┼─────────────────────┼─────────────────────────────┤│ 0 或 1 │ 期望的传输字节数 │ 剩余需要 arrive 的线程数 ││ 每次完成翻转 │ TMA 完成时递减 │ 每次 arrive 递减 │└─────────────┴─────────────────────┴─────────────────────────────┘完成条件: Pending TX Count == 0 AND Arrival Count == 0 → Phase Bit 翻转 6. 完整工作流程1234567891011121314151617181920212223242526272829303132333435Producer Warp Consumer Warp │ │ ▼ │producer_acquire(state) │ ├─ wait(empty_barrier[stage], phase) │ │ ← 等待 Consumer 释放空间 │ └─ arrive_and_expect_tx(full_barrier, bytes) │ ← 告知期望多少字节 │ │ │ ▼ │发起 TMA 加载 │ │ │ ▼ │TMA 完成 → 硬件自动 complete_tx │ │ ← pending_tx 减到 0 │ │ ← phase 翻转! │ │ ▼ │ consumer_try_wait(state) │ ← try_wait(full_barrier, phase) │ │ │ ▼ │ consumer_wait(state, token) │ ← 如果 WaitAgain，继续等待 │ │ │ ▼ │ 执行 MMA 计算 │ │ │ ▼ │ consumer_release(state) │ ← arrive(empty_barrier) │ ← arrival_count 减到 0 │ ← phase 翻转! ▼ │producer_acquire(next_state) │ ← 现在可以写入这个 stage │ 7. 多 Consumer 场景当有多个 Consumer Warp Group 时： 12345678// 初始化时empty_barrier[stage].init(arrival_count = num_consumers); // 例如 2// 运行时Consumer0: empty_barrier[stage].arrive() // count: 2→1Consumer1: empty_barrier[stage].arrive() // count: 1→0 → phase flip!// 只有所有 Consumer 都 arrive 后，Producer 才能继续 8. 源码参考 Pipeline 实现: include/cutlass/pipeline/sm90_pipeline.hpp Barrier 封装: include/cutlass/arch/barrier.h ClusterBarrier: barrier.h:341-532 ClusterTransactionBarrier: barrier.h:538-690","link":"/2024/12/23/pipeline-barrier-ptx-mapping/"}],"tags":[{"name":"CUTLASS","slug":"CUTLASS","link":"/tags/CUTLASS/"},{"name":"Epilogue","slug":"Epilogue","link":"/tags/Epilogue/"},{"name":"Fusion","slug":"Fusion","link":"/tags/Fusion/"},{"name":"EVT","slug":"EVT","link":"/tags/EVT/"},{"name":"Pipeline","slug":"Pipeline","link":"/tags/Pipeline/"},{"name":"mbarrier","slug":"mbarrier","link":"/tags/mbarrier/"},{"name":"PTX","slug":"PTX","link":"/tags/PTX/"}],"categories":[{"name":"CUTLASS","slug":"CUTLASS","link":"/categories/CUTLASS/"}],"pages":[{"title":"关于","text":"关于本站这是一个专注于 NVIDIA CUTLASS 和 CuTE 内部实现的学习笔记站点。 内容涵盖 Pipeline 同步机制: mbarrier、双 Barrier 架构、PTX 指令映射 Epilogue 融合: EVT (Expression Visitor Tree)、FusionCallbacks CuTE Tensor: Layout、Stride、TMA 联系方式 GitHub: DrXuQian","link":"/about/index.html"},{"title":"标签","text":"","link":"/tags/index.html"},{"title":"分类","text":"","link":"/categories/index.html"}]}